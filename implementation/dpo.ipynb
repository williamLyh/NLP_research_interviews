{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05e70680",
   "metadata": {},
   "source": [
    "# DPO off-policy Demostration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fb0557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from datasets import load_dataset\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# -----------------------\n",
    "# 配置\n",
    "# -----------------------\n",
    "MODEL_NAME = \"gpt2\"\n",
    "BATCH_SIZE = 2\n",
    "LR = 5e-6\n",
    "EPOCHS = 1\n",
    "BETA = 0.1\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# -----------------------\n",
    "# 加载模型和 tokenizer\n",
    "# -----------------------\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "\n",
    "# reference policy，冻结参数\n",
    "ref_model = AutoModelForCausalLM.from_pretrained(MODEL_NAME).to(DEVICE)\n",
    "ref_model.eval()  # 不训练\n",
    "\n",
    "# -----------------------\n",
    "# 加载偏好数据集\n",
    "# 数据集格式: { \"prompt\": ..., \"chosen\": ..., \"rejected\": ... }\n",
    "# -----------------------\n",
    "dataset = load_dataset(\"Dahoas/rm-static\")[\"train\"]\n",
    "\n",
    "# -----------------------\n",
    "# 数据处理函数\n",
    "# -----------------------\n",
    "def tokenize_pair(example):\n",
    "    prompt_ids = tokenizer(example[\"prompt\"], return_tensors=\"pt\").input_ids[0]\n",
    "    chosen_ids = tokenizer(example[\"chosen\"], return_tensors=\"pt\").input_ids[0]\n",
    "    rejected_ids = tokenizer(example[\"rejected\"], return_tensors=\"pt\").input_ids[0]\n",
    "    return {\n",
    "        \"prompt_ids\": prompt_ids,\n",
    "        \"chosen_ids\": chosen_ids,\n",
    "        \"rejected_ids\": rejected_ids\n",
    "    }\n",
    "\n",
    "dataset = dataset.map(tokenize_pair)\n",
    "\n",
    "# -----------------------\n",
    "# DataLoader\n",
    "# -----------------------\n",
    "def collate_fn(batch):\n",
    "    return batch\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# -----------------------\n",
    "# 优化器\n",
    "# -----------------------\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "# -----------------------\n",
    "# 训练循环\n",
    "# -----------------------\n",
    "for epoch in range(EPOCHS):\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        losses = []\n",
    "\n",
    "        for item in batch:\n",
    "            prompt_ids = item[\"prompt_ids\"].to(DEVICE)\n",
    "            chosen_ids = item[\"chosen_ids\"].to(DEVICE)\n",
    "            rejected_ids = item[\"rejected_ids\"].to(DEVICE)\n",
    "\n",
    "            # 模型 log probs\n",
    "            chosen_logits = model(input_ids=prompt_ids.unsqueeze(0), labels=chosen_ids.unsqueeze(0)).logits\n",
    "            rejected_logits = model(input_ids=prompt_ids.unsqueeze(0), labels=rejected_ids.unsqueeze(0)).logits\n",
    "\n",
    "            # reference log probs\n",
    "            with torch.no_grad():\n",
    "                chosen_logits_ref = ref_model(input_ids=prompt_ids.unsqueeze(0), labels=chosen_ids.unsqueeze(0)).logits\n",
    "                rejected_logits_ref = ref_model(input_ids=prompt_ids.unsqueeze(0), labels=rejected_ids.unsqueeze(0)).logits\n",
    "\n",
    "            # log_softmax\n",
    "            chosen_log_probs = F.log_softmax(chosen_logits, dim=-1)\n",
    "            rejected_log_probs = F.log_softmax(rejected_logits, dim=-1)\n",
    "            chosen_log_probs_ref = F.log_softmax(chosen_logits_ref, dim=-1)\n",
    "            rejected_log_probs_ref = F.log_softmax(rejected_logits_ref, dim=-1)\n",
    "\n",
    "            # 聚合序列 log prob\n",
    "            chosen_seq_log_prob = chosen_log_probs.gather(2, chosen_ids.unsqueeze(0).unsqueeze(-1)).squeeze(-1).sum()\n",
    "            rejected_seq_log_prob = rejected_log_probs.gather(2, rejected_ids.unsqueeze(0).unsqueeze(-1)).squeeze(-1).sum()\n",
    "            chosen_seq_log_prob_ref = chosen_log_probs_ref.gather(2, chosen_ids.unsqueeze(0).unsqueeze(-1)).squeeze(-1).sum()\n",
    "            rejected_seq_log_prob_ref = rejected_log_probs_ref.gather(2, rejected_ids.unsqueeze(0).unsqueeze(-1)).squeeze(-1).sum()\n",
    "\n",
    "            # DPO loss\n",
    "            log_ratio_chosen = chosen_seq_log_prob - chosen_seq_log_prob_ref\n",
    "            log_ratio_rejected = rejected_seq_log_prob - rejected_seq_log_prob_ref\n",
    "            loss = -torch.log(torch.sigmoid((log_ratio_chosen - log_ratio_rejected)/BETA))\n",
    "            losses.append(loss)\n",
    "\n",
    "        batch_loss = torch.stack(losses).mean()\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {batch_loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "608ca26f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
